{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIT_6_036_Spring_2019_Lab_11.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhuffy/website/blob/master/MIT_6_036_Spring_2019_Lab_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2XozwtJgh1-u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **MIT 6.036 Spring 2019: Lab 11**\n",
        "\n",
        "This colab notebook provides code and a framework for sections 2 and 3 of the lab.\n",
        "\n",
        "## **Setup**\n",
        "\n",
        "First, download the code distribution for this homework that contains test cases and helper functions.\n",
        "\n",
        "Run the next code block to download and import the code for this lab."
      ]
    },
    {
      "metadata": {
        "id": "rCJPrb3KhPmw",
        "colab_type": "code",
        "outputId": "e370a088-e3a6-4e9d-b0d6-7f56cbc1f78e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "!rm -rf code_for_lab11*\n",
        "!wget --quiet https://introml.odl.mit.edu/cat-soop/_static/6.036/labs/lab11/code_for_lab11.zip\n",
        "!unzip code_for_lab11.zip\n",
        "\n",
        "import os\n",
        "os.chdir('/content/code_for_lab11')\n",
        "os.getcwd()\n",
        "\n",
        "from sm import *\n",
        "from util import *\n",
        "from code_for_lab11 import *\n",
        "import numpy as np\n",
        "import _pickle as cPickle\n",
        "m = cPickle.load(open('models/food_rnn.p', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  code_for_lab11.zip\n",
            "   creating: code_for_lab11/\n",
            "  inflating: code_for_lab11/code_for_lab11.py  \n",
            "  inflating: code_for_lab11/metal_bands.txt  \n",
            "  inflating: code_for_lab11/companies.txt  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/code_for_lab11/\n",
            "  inflating: __MACOSX/code_for_lab11/._companies.txt  \n",
            "  inflating: code_for_lab11/.DS_Store  \n",
            "  inflating: code_for_lab11/MIT_classes.txt  \n",
            "  inflating: __MACOSX/code_for_lab11/._MIT_classes.txt  \n",
            "  inflating: code_for_lab11/util.py  \n",
            "   creating: code_for_lab11/__pycache__/\n",
            "  inflating: code_for_lab11/__pycache__/util.cpython-35.pyc  \n",
            "   creating: __MACOSX/code_for_lab11/__pycache__/\n",
            "  inflating: __MACOSX/code_for_lab11/__pycache__/._util.cpython-35.pyc  \n",
            "  inflating: code_for_lab11/__pycache__/sm.cpython-35.pyc  \n",
            "  inflating: __MACOSX/code_for_lab11/__pycache__/._sm.cpython-35.pyc  \n",
            "  inflating: code_for_lab11/__pycache__/code_for_lab11.cpython-35.pyc  \n",
            "  inflating: __MACOSX/code_for_lab11/__pycache__/._code_for_lab11.cpython-35.pyc  \n",
            "  inflating: code_for_lab11/__pycache__/util.cpython-37.pyc  \n",
            "  inflating: code_for_lab11/__pycache__/sm.cpython-37.pyc  \n",
            "  inflating: code_for_lab11/sm.py    \n",
            "  inflating: code_for_lab11/baskervilles.txt  \n",
            "  inflating: code_for_lab11/basicEnglish.txt  \n",
            "  inflating: code_for_lab11/simple_poem.txt  \n",
            "  inflating: code_for_lab11/food.txt  \n",
            "  inflating: code_for_lab11/mousquetaires.txt  \n",
            "   creating: code_for_lab11/models/\n",
            "  inflating: code_for_lab11/models/food_rnn.p  \n",
            "  inflating: code_for_lab11/models/metal_rnn.p  \n",
            "  inflating: code_for_lab11/models/MIT_classes_rnn.p  \n",
            "  inflating: code_for_lab11/models/companies_rnn.p  \n",
            "  inflating: __MACOSX/._code_for_lab11  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nOp2ZR1Nlc92",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Section 2, Problem B**\n",
        "\n",
        "Below, you will find definitions of a procedure called *test_linear_accumulator* for training an rnn with input and output sequences of the kind produced by Accumulator. (Alternatively, you can look at *code_for_lab11.py* of the code file available for download) Study this function, in particular, the definition of the RNN instance; compare to your choices in the previous question."
      ]
    },
    {
      "metadata": {
        "id": "Otw09SGC1gk3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# please evaluate this cell to see its output\n",
        "\n",
        "def test_linear_accumulator(num_steps = 10000,\n",
        "                            num_seqs = 100, seq_length = 5,\n",
        "                            step_size = .01):\n",
        "    # generate random training data: num_seqs of seq_length of random\n",
        "    # numbers between -0.5 and 0.5.\n",
        "    data = []\n",
        "    for _ in range(num_seqs):           \n",
        "        x = np.random.random((1, seq_length)) - 0.5 # seq in\n",
        "        y = np.zeros((1, seq_length))               # seq out\n",
        "        for j in range(seq_length):\n",
        "            y[0, j] = x[0, j] + (0.0 if j == 0 else y[0, j-1])\n",
        "        data.append((x, y))\n",
        "    # specify rnn\n",
        "    rnn = RNN(1, 1, 1, quadratic_loss, lambda z: z, quadratic_linear_gradient,\n",
        "              step_size, lambda z: z, lambda z: 1)\n",
        "    # train it\n",
        "    rnn.train_seq_to_seq(data, num_steps)\n",
        "    # print weights\n",
        "    print(\"Wsx: \", rnn.Wsx); print(\"Wss: \", rnn.Wss); print(\"Wo: \", rnn.Wo); print(\"Wss0: \", rnn.Wss0); print(\"Wo0: \", rnn.Wo0)\n",
        "    return rnn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z-OD7bEq1pSL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now run this function a few times, making sure that the training error is low and look at the final weights. Relate to the weights you chose above. Explain."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t1QR46mE1Vzj",
        "outputId": "088d38e6-9c7d-4b54-9fa9-894c8af767c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "test_linear_accumulator()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/10: training error 0.009419642217092069\n",
            "2/10: training error 2.017434482581991e-16\n",
            "3/10: training error 3.407002998387541e-20\n",
            "4/10: training error 0.00011324602922002858\n",
            "5/10: training error 1.519429166095417e-13\n",
            "6/10: training error 0.00018317478074818518\n",
            "7/10: training error 9.883320828810345e-11\n",
            "8/10: training error 3.807897409011255e-05\n",
            "9/10: training error 0.00015434682402794324\n",
            "Wsx:  [[1.34439139]]\n",
            "Wss:  [[1.]]\n",
            "Wo:  [[0.74383101]]\n",
            "Wss0:  [[2.95280514e-10]]\n",
            "Wo0:  [[9.86087395e-10]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<code_for_lab11.RNN at 0x7f42095aacf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "HZ629z-1xz4d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Section 3**"
      ]
    },
    {
      "metadata": {
        "id": "FtbW_gHiyyAq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For each of \n",
        "\n",
        "*   \"aaaaaaaaaa\"\n",
        "*   \"aabaaabbaaaababaabaa\"\n",
        "*   \"abcdefghijklmnopqrstuvwxyz\"\n",
        "*   \"abcabcabcabcabc\"\n",
        "\n",
        "train an RNN and assess the difficulty of learning each string. You may control *num_hidden* and *num_steps* to facilitate your training in the code below.\n"
      ]
    },
    {
      "metadata": {
        "id": "euRE-Zglzket",
        "colab_type": "code",
        "outputId": "07281fb5-80df-404c-88ff-739da2643155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1904
        }
      },
      "cell_type": "code",
      "source": [
        "test_word(\"aaaaaaaaaa\", interactive = False, num_hidden=1, num_steps=10000, step_size=0.005)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/10: training error 0.2942080588570154\n",
            "2/10: training error 0.027508181989669676\n",
            "3/10: training error 0.008099196358950277\n",
            "4/10: training error 0.0037993239238083482\n",
            "5/10: training error 0.0019501673676529298\n",
            "6/10: training error 0.001048624181199073\n",
            "7/10: training error 0.0005796283226812455\n",
            "8/10: training error 0.0003260984332101961\n",
            "9/10: training error 0.0001856715709219592\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n",
            "aaaaaaaaaa\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<code_for_lab11.RNN at 0x7f4209512630>,\n",
              " <code_for_lab11.OneHotCodec at 0x7f4208d43da0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "--_tiGbyzoCW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_word(\"aabaaabbaaaababaabaa\", interactive = False, num_hidden=1, num_steps=10000, step_size=0.005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aGAyQxO7zqSG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_word(\"abcdefghijklmnopqrstuvwxyz\", interactive = False, num_hidden=1, num_steps=10000, step_size=0.005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9BI7pgDbzsim",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_word(\"abcabcabcabcabc\", interactive = False, num_hidden=1, num_steps=10000, step_size=0.005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zuA9fE44zdUb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 3D\n",
        "\n",
        "The *test_class_names* function uses a file <a href=\"https://docs.google.com/document/d/1X1CxoreisEHRSwFDzbh3SxnBbTOILNbVbjD_Ef0fx9k/edit?usp=sharing\">MIT_classes.txt</a> (which is a collection of names of classes taught at MIT) for training\n",
        "and generates new names. Experiment with different values of num_steps; more steps gives better results. Try it in interactive mode; it's more fun. Note the difference between starting with a capital letter versus lower case letter.\n",
        "\n",
        "**In running *test_class_names*, first try with *train=True*; you can train the RNN yourself with this option. If this takes too much time, run  *test_class_names* with *train=False*; you can simply load a pre-trained model with this option. **\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "oj8wsxKr18Mj",
        "colab_type": "code",
        "outputId": "89b8dd13-6078-4a67-bb5a-4bf94045baa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "test_class_names(interactive = True, interactive_top5 = False, \n",
        "           split=0, num_hidden = 150, \n",
        "           num_steps = 20000, step_size = .001, train=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/10: training error 2.6798431376463046\n",
            "2/10: training error 1.9005631016920619\n",
            "3/10: training error 1.5972020963129576\n",
            "4/10: training error 1.4384366598684983\n",
            "5/10: training error 1.3200216253130523\n",
            "6/10: training error 1.2428906553135863\n",
            "7/10: training error 1.1878505916132391\n",
            "8/10: training error 1.1710052121693473\n",
            "9/10: training error 1.111254453500892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZEwfEUrzx2zr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_class_names(interactive = True, interactive_top5 = False,\n",
        "           split=0, num_hidden = 150, \n",
        "           num_steps = 20000, step_size = .001, train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rxC8sgJV0WOP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 3E\n",
        "\n",
        "The *test_food* function uses a file <a href=\"https://docs.google.com/spreadsheets/d/12eomCfekSdqTlOB4Xwp3n7_FN0SVdVrTDLVUBq-1jyw/edit?usp=sharing\">food.txt</a> of recipe names. Experiment with different values of num_steps; more steps gives better results. Try it in interactive mode; it's more fun. Note the difference between starting with a capital letter versus lower case letter.\n",
        "\n",
        "**In running *test_food*, first try with *train=True*; you can train the RNN yourself with this option. If this takes too much time, run  *test_food* with *train=False*; you can simply load a pre-trained model with this option. **\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "T-G-bm0p1_FT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_food(interactive = True, interactive_top5 = False, \n",
        "          split=0, num_hidden = 150, \n",
        "          num_steps = 20000, step_size = .001, train=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pHRpZudK0iye",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_food(interactive = True, interactive_top5 = False, \n",
        "          split=0, num_hidden = 150, \n",
        "          num_steps = 20000, step_size = .001, train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9eFwDWYXVB15",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 3F\n",
        "\n",
        "The <code>test_comapny_names</code> function uses the file <a href=\"https://docs.google.com/spreadsheets/d/16wbhwRwu5AP4gydX9buHZj884v48HURaalYtKmdT8r0/edit?usp=sharing\">companies.txt</a> of company names. Experiment with different\n",
        "values of num_steps; more steps gives better results.  Try it in\n",
        "interactive mode, by setting <code>interactive=True</code> but still set <code>interactive_top5=False</code>; it's more fun. Note the difference between starting\n",
        "with a capital letter versus lower case letter.\n",
        "\n",
        "**In running *test_company_names*, first try with *train=True*; you can train the RNN yourself with this option. If this takes too much time, run  *test_company_names* with *train=False*; you can simply load a pre-trained model with this option. **\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "U0gURYiSvgXk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_company_names(interactive = True, interactive_top5 = False, \n",
        "          split=0, num_hidden = 150, \n",
        "          num_steps = 20000, step_size = .001, train=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J7BIAXvSvge0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_company_names(interactive = True, interactive_top5 = False, \n",
        "          split=0, num_hidden = 150, \n",
        "          num_steps = 20000, step_size = .001, train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BFYBVV4Svfsh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 3G\n",
        "\n",
        "Now run one of <code>test_class_names, test_food, test_comapny_names</code> with <code>interactive_top5=True</code>; play with them for a while. Can you notice the mechanism of how these functions generate their output? \n",
        "\n",
        "Use the cell below to run one of <code>test_class_names, test_food, test_comapny_names</code> with <code>interactive_top5=True</code>!"
      ]
    },
    {
      "metadata": {
        "id": "m4ry0vweVOl-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_class_names(interactive = True, interactive_top5 = True, split=0, num_hidden = 150, num_steps = 20000, step_size = .001, train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ug4mvoGaVeKR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_food(interactive = True, interactive_top5 = True, split=0, num_hidden = 150, num_steps = 20000, step_size = .001, train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c3R3Hmu0xvht",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_company_names(interactive = True, interactive_top5 = True, split=0, num_hidden = 150, num_steps = 20000, step_size = .001, train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}